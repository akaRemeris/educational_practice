{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = './data/'\n",
    "MODELS_PATH = './models/'\n",
    "TRAIN_SIZE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "init_random_seed()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis\n",
    "By the first glance, fake news mostly associated with politics, political sedition, contains a lot of entities related to organizations or well-known (often political) persons. (Neural Meduza, is that you?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASETS_PATH + 'train.csv', 'r', encoding='utf-8') as fstream:\n",
    "    freader = csv.reader(fstream, delimiter='\\t')\n",
    "    next(freader)\n",
    "    general_docs = []\n",
    "    general_labels = []\n",
    "    for obs in freader:\n",
    "        general_docs.append(obs[0])\n",
    "        general_labels.append(int(obs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASETS_PATH + 'test.csv', 'r', encoding='utf-8') as fstream:\n",
    "    freader = csv.reader(fstream, delimiter='\\t')\n",
    "    next(freader)\n",
    "    test_docs = []\n",
    "    test_labels = []\n",
    "    for obs in freader:\n",
    "        test_docs.append(obs[0])\n",
    "        test_labels.append(int(obs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Москвичу Владимиру Клутину пришёл счёт за вмешательство в американские выборы',\n",
       "  'Агент Кокорина назвал езду по встречке житейской историей',\n",
       "  'Госдума рассмотрит возможность введения секретных статей Уголовного кодекса'],\n",
       " [1, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_docs[:3], general_labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5758, 1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(general_docs), len(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_labels = np.array(general_labels)\n",
    "label_counts = np.unique(general_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.pie(label_counts[1], labels=label_counts[1], autopct='%1.1f%%');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick thoughts:\n",
    "* Small dataset;\n",
    "* Balanced labels, so **accuracy** metric remains representative enough;\n",
    "* Short sequences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Eval split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_random_seed(0)\n",
    "random.shuffle(general_docs)\n",
    "init_random_seed(0)\n",
    "random.shuffle(general_labels)\n",
    "TRAIN_ABS_SIZE = int(len(general_docs) * TRAIN_SIZE)\n",
    "\n",
    "train_texts = general_docs[:TRAIN_ABS_SIZE]\n",
    "eval_texts = general_docs[TRAIN_ABS_SIZE:]\n",
    "train_labels = general_labels[:TRAIN_ABS_SIZE]\n",
    "eval_labels = general_labels[TRAIN_ABS_SIZE:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with BOW \n",
    "1. Lemmatization to reduce vocabulary - baseline-model is simple enough, so lemmatizing won't cause any large information losses.\n",
    "2. Filtering + Vectorization\n",
    "3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Uer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text normalization - lemmatizing vs stemming.\n",
    "\n",
    "1. Russian is the language with high word-inflection, so stemming might be too harsh procedure, even tho quick enough.\n",
    "2. Dataset is quite small and sequences are short, so lemmatizing won't take long to produce, and will greatly optimize vocabulary size.\n",
    "\n",
    "It is proposed to use the same lemmatizer as been used in spacy lib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorphy = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_normalizer(word):\n",
    "    return pymorphy.parse(word)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, stopwords=None) -> None:\n",
    "        self.word_normalizer = word_normalizer\n",
    "        self.stopwords = set(stopwords)\n",
    "    \n",
    "    def remove_stopwords(self, document, min_len=4):\n",
    "\n",
    "        if self.stopwords is None:\n",
    "            return document        \n",
    "        document = [token\n",
    "                for token in document\n",
    "                if token not in self.stopwords and len(token) >= min_len]\n",
    "        return document    \n",
    "\n",
    "    def __call__(self, document):\n",
    "\n",
    "        tokenized_document = word_tokenize(document)\n",
    "        tokenized_document = self.remove_stopwords(tokenized_document)\n",
    "        \n",
    "        return [self.word_normalizer(token) for token in tokenized_document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кудрин призвал перевести Россию на ветроэнергетику прямо сейчас\n",
      "['кудрин', 'призвать', 'перевести', 'россия', 'ветроэнергетика', 'прямо']\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0])\n",
    "print(tokenizer(train_texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = [tokenizer(doc) for doc in train_texts]\n",
    "eval_tokenized = [tokenizer(doc) for doc in eval_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5182, 576)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tokenized), len(eval_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5182, 10068), (576, 10068))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_tokenizer = lambda x: x\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=pseudo_tokenizer,\n",
    "    lowercase=False,\n",
    "    max_df=0.7\n",
    "    )\n",
    "    \n",
    "X_train = vectorizer.fit_transform(train_tokenized)\n",
    "X_eval = vectorizer.transform(eval_tokenized)\n",
    "X_train.shape, X_eval.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model\n",
    "\n",
    "Motivation behind SVM:\n",
    "1. Binary classification\n",
    "2. TF-IDF contains large amount of sparse features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_sklearn_clf(clf, X_train, y_train, X_eval, y_eval):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    train_preds = clf.predict(X_train)\n",
    "    eval_preds = clf.predict(X_eval)\n",
    "\n",
    "    train_accuracy = (train_preds == np.array(y_train)).mean()\n",
    "    eval_accuracy = (eval_preds == np.array(y_eval)).mean()\n",
    "    print('Train accuracy:', train_accuracy)\n",
    "    print('Eval accuracy:', eval_accuracy)\n",
    "    print('Train f1_score:', f1_score(y_eval, eval_preds))\n",
    "    print('Eval f1_score:', f1_score(y_eval, eval_preds))\n",
    "    print('Train auc:', roc_auc_score(y_eval, eval_preds))\n",
    "    print('Eval auc:', roc_auc_score(y_eval, eval_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81318681, 0.84332689, 0.82457879, 0.84179104, 0.82514735])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm_clf, X_train, train_labels, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9984561945194905\n",
      "Eval accuracy: 0.8315972222222222\n",
      "Train f1_score: 0.8318890814558058\n",
      "Eval f1_score: 0.8318890814558058\n",
      "Train auc: 0.8316252712804436\n",
      "Eval auc: 0.8316252712804436\n"
     ]
    }
   ],
   "source": [
    "svm_clf = svm.SVC()\n",
    "train_eval_sklearn_clf(svm_clf, X_train, train_labels, X_eval, eval_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w2v + BiGRU\n",
    "\n",
    "<p>Possibility to use embeddings that are pre-trained on a much larger dataset, gives the W2V method an advantage due to transfer learning, in compare to BOW.</p>\n",
    "\n",
    "Optimal utilization of W2V embeddings may be brought by a **light** and **bidirectional** RNN due to:\n",
    "1. Sequences are short enough, so there is no need in Long Short-Term memory\n",
    "2. Russian language is quite free regarding the word order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "import zipfile\n",
    "import gensim\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_WEIGTHS_NAME = 'gru_fakenews_clf.pt'\n",
    "MAX_EPOCH = 10\n",
    "BATCH_SIZE = 128\n",
    "PAD_TOKEN = '<PAD>'\n",
    "BOS_TOKEN = '<BOS>'\n",
    "EOS_TOKEN = '<EOS>'\n",
    "UNK_TOKEN = '<UNK>'\n",
    "SPECIAL_TOKENS = [PAD_TOKEN, BOS_TOKEN, EOS_TOKEN, UNK_TOKEN]\n",
    "special_tokens_map = dict(zip(SPECIAL_TOKENS, [i for i in range(len(SPECIAL_TOKENS))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_seed(value=0):\n",
    "    random.seed(value)\n",
    "    np.random.seed(value)\n",
    "    torch.manual_seed(value)\n",
    "    torch.cuda.manual_seed(value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "init_random_seed()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "train_tokenized = [word_tokenizer.tokenize(doc.lower()) for doc in train_texts]\n",
    "eval_tokenized = [word_tokenizer.tokenize(doc.lower()) for doc in eval_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Dictionary(train_tokenized)\n",
    "vocabulary.filter_extremes(no_above=0.7, no_below=2)\n",
    "vocabulary.patch_with_special_tokens(special_tokens_map)\n",
    "VOCABULARY_SIZE = len(vocabulary)\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_embeddings = np.zeros(shape=[VOCABULARY_SIZE, EMBEDDING_DIM],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is no pre-trained weights for model, load fastText embeddings\n",
    "if PRETRAINED_WEIGTHS_NAME is None:\n",
    "    model_url = 'http://vectors.nlpl.eu/repository/11/187.zip'\n",
    "    # wget.download(model_url)\n",
    "    w2v_model = gensim.models.KeyedVectors.load(MODELS_PATH + '/187/model.model')\n",
    "    for word in vocabulary.token2id.keys():\n",
    "        if word in w2v_model:\n",
    "            word_emb = w2v_model[word]\n",
    "            word_idx = vocabulary.token2id[word]\n",
    "            numpy_embeddings[word_idx] = word_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5787, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = [vocabulary.doc2idx(doc, unknown_word_index=special_tokens_map[UNK_TOKEN]) for doc in train_tokenized]\n",
    "eval_encoded = [vocabulary.doc2idx(doc, unknown_word_index=special_tokens_map[UNK_TOKEN]) for doc in eval_tokenized]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.LongTensor([special_tokens_map[BOS_TOKEN]] + self.features[idx] + [special_tokens_map[EOS_TOKEN]])\n",
    "        targets = torch.FloatTensor([self.targets[idx]])\n",
    "        return (features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(data):\n",
    "    features, labels = zip(*data)\n",
    "    seq_lens = [len(seq) for seq in features]\n",
    "    features = torch.nn.utils.rnn.pad_sequence(features, batch_first=True, padding_value=special_tokens_map[PAD_TOKEN])\n",
    "    labels = torch.cat(labels)\n",
    "    return {'input_ids': features, 'lengths': seq_lens, 'labels': labels} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SequenceDataset(train_encoded, train_labels)\n",
    "eval_dataset = SequenceDataset(eval_encoded, eval_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, collate_fn=custom_collate)\n",
    "eval_dataloader = DataLoader(eval_dataset, BATCH_SIZE, shuffle=True, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   1, 5784,    3,  ...,    0,    0,    0],\n",
       "         [   1, 3739,    3,  ...,    0,    0,    0],\n",
       "         [   1,   47,    3,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   1, 1535,    3,  ...,    0,    0,    0],\n",
       "         [   1, 2686, 2689,  ...,    0,    0,    0],\n",
       "         [   1,  168,    3,  ...,    0,    0,    0]]),\n",
       " 'lengths': [12,\n",
       "  9,\n",
       "  8,\n",
       "  12,\n",
       "  7,\n",
       "  13,\n",
       "  8,\n",
       "  11,\n",
       "  12,\n",
       "  19,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  6,\n",
       "  13,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  10,\n",
       "  17,\n",
       "  22,\n",
       "  16,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  6,\n",
       "  8,\n",
       "  9,\n",
       "  7,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  12,\n",
       "  19,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  12,\n",
       "  13,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  8,\n",
       "  13,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  13,\n",
       "  15,\n",
       "  15,\n",
       "  14,\n",
       "  8,\n",
       "  14,\n",
       "  11,\n",
       "  7,\n",
       "  13,\n",
       "  12,\n",
       "  23,\n",
       "  14,\n",
       "  7,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  7,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  15,\n",
       "  13,\n",
       "  12,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  7,\n",
       "  9,\n",
       "  12,\n",
       "  16,\n",
       "  10,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  16,\n",
       "  8,\n",
       "  9,\n",
       "  14,\n",
       "  9,\n",
       "  31,\n",
       "  10,\n",
       "  13,\n",
       "  10,\n",
       "  6,\n",
       "  10,\n",
       "  8,\n",
       "  17,\n",
       "  15,\n",
       "  13,\n",
       "  11,\n",
       "  11,\n",
       "  14,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  19,\n",
       "  12,\n",
       "  8,\n",
       "  14,\n",
       "  13,\n",
       "  14,\n",
       "  11,\n",
       "  12,\n",
       "  14,\n",
       "  9,\n",
       "  11,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  17],\n",
       " 'labels': tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "         1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "         0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "         1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1.])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contextualizer(torch.nn.Module):\n",
    "    def __init__(self, vocabulary_size, targets_size, embedding_size, hidden_state_size, embeddings, dropout=0.1, device='cuda') -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.embeddings = torch.nn.Embedding.from_pretrained(torch.FloatTensor(embeddings), freeze=True)\n",
    "        self.embedding_dropout = torch.nn.Dropout(dropout)\n",
    "        self.backbone = torch.nn.GRU(embedding_size, hidden_state_size, batch_first=True, bidirectional=True)\n",
    "        self.out_linear = torch.nn.Linear(2*hidden_state_size, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, padded_inp, lengths):\n",
    "        batch_size, seq_len = padded_inp.shape\n",
    "        \n",
    "        inp_embs = self.embeddings(padded_inp)\n",
    "        inp_embs = self.embedding_dropout(inp_embs)\n",
    "\n",
    "        packed_padded_inp = torch.nn.utils.rnn.pack_padded_sequence(inp_embs, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_h_matrices, last_h_state = self.backbone(packed_padded_inp)\n",
    "\n",
    "        h_matrices, _ = torch.nn.utils.rnn.pad_packed_sequence(packed_h_matrices, batch_first=True)\n",
    "\n",
    "        last_h_state = torch.cat([last_h_state[0], last_h_state[1]], -1)        \n",
    "        h_proj = self.out_linear(last_h_state)\n",
    "        return h_proj"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_random_seed()\n",
    "model = Contextualizer(VOCABULARY_SIZE, 1, embedding_size=EMBEDDING_DIM, hidden_state_size=2*EMBEDDING_DIM, embeddings=numpy_embeddings, dropout=0.2).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PRETRAINED_WEIGTHS_NAME is not None:\n",
    "    model.load_state_dict(torch.load(MODELS_PATH + PRETRAINED_WEIGTHS_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4984501"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "sum(reduce(lambda x, y: x*y,  par.shape) for par in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Train/Eval stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 1 \t| epoch train loss: 0.4947 \t| epoch eval loss:  0.339 \t| train_accuracy: 0.76 \t| eval_accuracy: 0.82\n",
      "Epoch Number: 2 \t| epoch train loss: 0.3369 \t| epoch eval loss: 0.3182 \t| train_accuracy: 0.85 \t| eval_accuracy: 0.85\n",
      "Epoch Number: 3 \t| epoch train loss:  0.281 \t| epoch eval loss: 0.2925 \t| train_accuracy: 0.88 \t| eval_accuracy: 0.87\n",
      "Epoch Number: 4 \t| epoch train loss: 0.2482 \t| epoch eval loss:  0.311 \t| train_accuracy: 0.9 \t| eval_accuracy: 0.85\n",
      "Epoch Number: 5 \t| epoch train loss: 0.2001 \t| epoch eval loss: 0.3474 \t| train_accuracy: 0.92 \t| eval_accuracy: 0.85\n",
      "Epoch 00006: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch Number: 6 \t| epoch train loss: 0.1657 \t| epoch eval loss: 0.4213 \t| train_accuracy: 0.94 \t| eval_accuracy: 0.85\n",
      "Epoch Number: 7 \t| epoch train loss: 0.1181 \t| epoch eval loss: 0.3263 \t| train_accuracy: 0.96 \t| eval_accuracy: 0.87\n",
      "Epoch Number: 8 \t| epoch train loss: 0.09428 \t| epoch eval loss:  0.359 \t| train_accuracy: 0.97 \t| eval_accuracy: 0.87\n",
      "Epoch 00009: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch Number: 9 \t| epoch train loss: 0.08436 \t| epoch eval loss: 0.3542 \t| train_accuracy: 0.97 \t| eval_accuracy: 0.87\n",
      "Epoch Number: 10 \t| epoch train loss: 0.07783 \t| epoch eval loss: 0.3678 \t| train_accuracy: 0.98 \t| eval_accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "assert PRETRAINED_WEIGTHS_NAME is None, 'Model training is not intended, skip this cell'\n",
    "train_loss_log = []\n",
    "eval_loss_log = []\n",
    "for epoch_id in range(MAX_EPOCH):\n",
    "    epoch_loss = 0\n",
    "    train_predicted_labels = []\n",
    "    train_target_labels = []\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        inp_ids = batch['input_ids'].to(model.device)\n",
    "        lens = batch['lengths']\n",
    "        labels = batch['labels'].to(model.device)\n",
    "        out_logits = model(inp_ids, lens)\n",
    "        loss = loss_fn(out_logits.flatten(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        train_predicted_labels += (torch.sigmoid(out_logits.flatten()) > 0.5).float().tolist()\n",
    "        train_target_labels += labels.tolist()\n",
    "    train_loss_log.append(epoch_loss/(batch_idx + 1))\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    eval_predicted_labels = []\n",
    "    eval_target_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(eval_dataloader):\n",
    "            inp_ids = batch['input_ids'].to(model.device)\n",
    "            lens = batch['lengths']\n",
    "            labels = batch['labels'].to(model.device)\n",
    "            out_logits = model(inp_ids, lens)\n",
    "            loss = loss_fn(out_logits.flatten(), labels)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            eval_predicted_labels += (torch.sigmoid(out_logits.flatten()) > 0.5).float().tolist()\n",
    "            eval_target_labels += labels.tolist()\n",
    "        eval_loss_log.append(epoch_loss/(batch_idx + 1))\n",
    "        lr_scheduler.step(eval_loss_log[-1])\n",
    "\n",
    "    print(\"Epoch Number: {} \\t| epoch train loss: {:6.4} \\t| epoch eval loss: {:6.4} \\t| train_accuracy: {:3.2} \\t| eval_accuracy: {:3.2}\"\\\n",
    "            .format(\n",
    "                epoch_id + 1, \n",
    "                train_loss_log[-1], \n",
    "                eval_loss_log[-1], \n",
    "                (np.array(train_predicted_labels) == np.array(train_target_labels)).mean(),\n",
    "                (np.array(eval_predicted_labels) == np.array(eval_target_labels)).mean()\n",
    "            )\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26c099a7c10>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eval_loss_log)\n",
    "plt.plot(train_loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "target_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(eval_dataloader):\n",
    "            inp_ids = batch['input_ids'].to(model.device)\n",
    "            lens = batch['lengths']\n",
    "            labels = batch['labels'].to(model.device)\n",
    "            out_logits = model(inp_ids, lens)\n",
    "            loss = loss_fn(out_logits.flatten(), labels)\n",
    "\n",
    "            predicted_labels += (torch.sigmoid(out_logits.flatten()) > 0.5).float().tolist()\n",
    "            target_labels += labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695652173913043"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.array(predicted_labels),np.array(target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contextualizer(\n",
       "  (embeddings): Embedding(5787, 300)\n",
       "  (embedding_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (backbone): GRU(300, 600, batch_first=True, bidirectional=True)\n",
       "  (out_linear): Linear(in_features=1200, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODELS_PATH + 'gru_fakenews_clf.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test predictions run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   1,  520,  780,  ...,    0,    0,    0],\n",
       "         [   1,    3,  135,  ...,    0,    0,    0],\n",
       "         [   1,  186,    3,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   1, 1829,  658,  ...,    0,    0,    0],\n",
       "         [   1, 5784, 1984,  ...,    0,    0,    0],\n",
       "         [   1,    3,  437,  ...,    0,    0,    0]]),\n",
       " 'lengths': [11,\n",
       "  17,\n",
       "  13,\n",
       "  16,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  23,\n",
       "  10,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  6,\n",
       "  22,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  13,\n",
       "  13,\n",
       "  11,\n",
       "  10,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  12,\n",
       "  15,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  12,\n",
       "  8,\n",
       "  9,\n",
       "  15,\n",
       "  18,\n",
       "  8,\n",
       "  6,\n",
       "  6,\n",
       "  15,\n",
       "  11,\n",
       "  15,\n",
       "  6,\n",
       "  12,\n",
       "  9,\n",
       "  11,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  16,\n",
       "  11,\n",
       "  9,\n",
       "  9,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  15,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  16,\n",
       "  16,\n",
       "  11,\n",
       "  7,\n",
       "  10,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  9,\n",
       "  11,\n",
       "  10,\n",
       "  7,\n",
       "  11,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  14,\n",
       "  11,\n",
       "  7,\n",
       "  16,\n",
       "  11,\n",
       "  11,\n",
       "  13,\n",
       "  15,\n",
       "  8,\n",
       "  10,\n",
       "  8,\n",
       "  9,\n",
       "  13,\n",
       "  9,\n",
       "  10,\n",
       "  14,\n",
       "  15,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  8,\n",
       "  11,\n",
       "  13,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  14,\n",
       "  21,\n",
       "  12,\n",
       "  14,\n",
       "  9,\n",
       "  17,\n",
       "  8,\n",
       "  7,\n",
       "  12,\n",
       "  15,\n",
       "  20,\n",
       "  12,\n",
       "  11,\n",
       "  15,\n",
       "  13,\n",
       "  8,\n",
       "  11,\n",
       "  11,\n",
       "  9],\n",
       " 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tokenized = [word_tokenizer.tokenize(doc.lower()) for doc in test_docs]\n",
    "test_encoded = [vocabulary.doc2idx(doc, unknown_word_index=special_tokens_map[UNK_TOKEN]) for doc in test_tokenized]\n",
    "test_dataset = SequenceDataset(test_encoded, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False, collate_fn=custom_collate)\n",
    "next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "predicted_proba = []\n",
    "target_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader):\n",
    "            inp_ids = batch['input_ids'].to(model.device)\n",
    "            lens = batch['lengths']\n",
    "            labels = batch['labels'].to(model.device)\n",
    "            out_logits = model(inp_ids, lens)\n",
    "\n",
    "            predicted_proba += torch.sigmoid(out_logits.flatten()).tolist()\n",
    "            predicted_labels += (torch.sigmoid(out_logits.flatten()) > 0.5).int().tolist()\n",
    "            target_labels += labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there was any unintended shuffles\n",
    "assert (np.array(target_labels) == test_labels).mean() == 1, 'Original order is violated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_df = pd.DataFrame(dict(zip(['title', 'prob_fake', 'is_fake'], [test_docs, predicted_proba, predicted_labels])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>prob_fake</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Роскомнадзор представил реестр сочетаний цвето...</td>\n",
       "      <td>0.858530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ночью под Минском на президентской горе Белара...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Бывший спичрайтер Юрия Лозы рассказал о трудно...</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Сельская церковь, собравшая рекордно низкое ко...</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Акции Google рухнули после объявления о переза...</td>\n",
       "      <td>0.691313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Прокуратура заподозрила Явлинского в авторитар...</td>\n",
       "      <td>0.301758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>В День Победы стратегические ракетоносцы Ту-16...</td>\n",
       "      <td>0.974203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>СК возбудил дело против авиакомпании «Победа» ...</td>\n",
       "      <td>0.943087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Криптомонетный двор Туркменистана выпустил юби...</td>\n",
       "      <td>0.133634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Deutsche Bahn заплатит рекордный штраф за чтен...</td>\n",
       "      <td>0.987249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  prob_fake  is_fake\n",
       "0    Роскомнадзор представил реестр сочетаний цвето...   0.858530        1\n",
       "1    Ночью под Минском на президентской горе Белара...   0.999998        1\n",
       "2    Бывший спичрайтер Юрия Лозы рассказал о трудно...   0.999829        1\n",
       "3    Сельская церковь, собравшая рекордно низкое ко...   0.999985        1\n",
       "4    Акции Google рухнули после объявления о переза...   0.691313        1\n",
       "..                                                 ...        ...      ...\n",
       "995  Прокуратура заподозрила Явлинского в авторитар...   0.301758        0\n",
       "996  В День Победы стратегические ракетоносцы Ту-16...   0.974203        1\n",
       "997  СК возбудил дело против авиакомпании «Победа» ...   0.943087        1\n",
       "998  Криптомонетный двор Туркменистана выпустил юби...   0.133634        0\n",
       "999  Deutsche Bahn заплатит рекордный штраф за чтен...   0.987249        1\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('predictions.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_scratch_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81ee5fcf96e0950120182c502807a58795a1dae9c5834757bcd4d70878f34635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
